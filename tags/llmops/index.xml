<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>LLMOps on Arjun's Blog</title><link>https://arjunsehajpal.com/tags/llmops/</link><description>Recent content in LLMOps on Arjun's Blog</description><generator>Hugo</generator><language>en</language><lastBuildDate>Mon, 08 Jul 2024 00:38:16 +0530</lastBuildDate><atom:link href="https://arjunsehajpal.com/tags/llmops/index.xml" rel="self" type="application/rss+xml"/><item><title>LLM Evaluation 02: RAG</title><link>https://arjunsehajpal.com/posts/llm-evaluation-02/</link><pubDate>Mon, 08 Jul 2024 00:38:16 +0530</pubDate><guid>https://arjunsehajpal.com/posts/llm-evaluation-02/</guid><description>&lt;p&gt;Once perceived as a hack, Retrieval-Augmented Generation (RAG) has now become an essential component of LLM applications. It has been most impactful in the area of closed-domain question answering, which was considered tricky due to static knowledge bases and limited context understanding. Since RAG systems retrieve information in real-time from a continuously updated corpus (thanks to vector databases), there is no need for manual updates to a static knowledge base. By combining retrieval and generation, RAG-enabled LLM systems can better understand the context and nuances of complex queries, leading to more accurate and relevant answers. The effectiveness of RAG-enabled LLM systems has been so significant that entire ecosystems of startups and vector database providers have emerged around them.&lt;/p&gt;</description></item><item><title>LLM Evaluation 01: Overview</title><link>https://arjunsehajpal.com/posts/llm-evaluation-overview/</link><pubDate>Mon, 18 Mar 2024 00:38:16 +0530</pubDate><guid>https://arjunsehajpal.com/posts/llm-evaluation-overview/</guid><description>&lt;p&gt;LLMs have been all the rage now. Whether you believe in the potential of LLMs or you are still in the camp of sceptics, it doesn’t matter. It’s the stakeholders’ opinion about LLMs that matters. This is because LLMs make it quite easy to “wow the users” and attract them to the product. So, they facilitate onboarding new users to the product. However, it is the trust that retains the users. And, as most of us know by now, LLMs make numerous mistakes. As the complexity rises and users receive incorrect answers frequently, they won’t trust the system and will revert to the tools they were using before.&lt;/p&gt;</description></item></channel></rss>